x-veld:
  code:
    description: "downloading wikipedia archive and extracting each article to a json file."
    topics:
      - "NLP"
      - "Machine Learning"
      - "ETL"

    outputs:
      - volume: /veld/output/
        description: "a folder containing json files, where each file contains the contents of a
          wikipedia article"
        file_type: "json"
        contents: 
          - "NLP training data"
          - "raw text"

    settings:
      - environment: wikipedia_dump_url
        description: "url to a wikipdedia dump download, from https://dumps.wikimedia.org/"
        env_type: "str"
      - environment: out_data_description
        description: "short human description for the data and its purpose, will be persisted in a
          data veld yaml"
        env_type: "str"
        optional: true
      

services:
  veld_download_and_extract:
    build: .
    volumes:
      - ./src/:/veld/code/:z
      - ./data/wikipedia_json/:/veld/output/:z
    command: /veld/code/download_and_extract.sh
    environment:
      wikipedia_dump_url: null
      out_data_description: null

